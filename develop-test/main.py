import requests
from datetime import datetime, timedelta
import time
from tqdm import tqdm
import json
import os
from functools import wraps
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
from collections import defaultdict
import concurrent.futures
import threading
from urllib.parse import urlencode
import hashlib

# Cache sistemi
cache_dir = "cache"
if not os.path.exists(cache_dir):
    os.makedirs(cache_dir)

cache_lock = threading.Lock()

def get_cache_key(lat, lon, date_str):
    """Cache anahtarÄ± oluÅŸtur"""
    key_string = f"{lat}_{lon}_{date_str}"
    return hashlib.md5(key_string.encode()).hexdigest()

def get_from_cache(cache_key):
    """Cache'den veri oku"""
    cache_file = os.path.join(cache_dir, f"{cache_key}.json")
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r') as f:
                return json.load(f)
        except:
            return None
    return None

def save_to_cache(cache_key, data):
    """Cache'e veri kaydet"""
    cache_file = os.path.join(cache_dir, f"{cache_key}.json")
    try:
        with cache_lock:
            with open(cache_file, 'w') as f:
                json.dump(data, f)
    except:
        pass

# Thread-safe adaptive rate limiting
class AdaptiveRateLimiter:
    def __init__(self, initial_calls_per_second=1):
        self.calls_per_second = initial_calls_per_second
        self.min_interval = 1.0 / self.calls_per_second
        self.last_called = 0.0
        self.lock = threading.Lock()
        self.consecutive_429s = 0
        self.last_success_time = time.time()
    
    def wait_if_needed(self):
        with self.lock:
            elapsed = time.time() - self.last_called
            wait_time = self.min_interval - elapsed
            if wait_time > 0:
                time.sleep(wait_time)
            self.last_called = time.time()
    
    def report_429(self):
        """429 hatasÄ± aldÄ±ÄŸÄ±nda rate limiting'i yavaÅŸlat"""
        with self.lock:
            self.consecutive_429s += 1
            # Her 429'da daha yavaÅŸ yap
            self.calls_per_second = max(0.2, self.calls_per_second * 0.5)
            self.min_interval = 1.0 / self.calls_per_second
            print(f"âš ï¸ Rate limit dÃ¼ÅŸÃ¼rÃ¼ldÃ¼: {self.calls_per_second:.2f} calls/sec")
    
    def report_success(self):
        """BaÅŸarÄ±lÄ± Ã§aÄŸrÄ±da rate'i yavaÅŸÃ§a artÄ±r"""
        with self.lock:
            self.last_success_time = time.time()
            if self.consecutive_429s > 0:
                self.consecutive_429s = max(0, self.consecutive_429s - 1)
                if self.consecutive_429s == 0:
                    # YavaÅŸÃ§a geri artÄ±r
                    self.calls_per_second = min(2.0, self.calls_per_second * 1.1)
                    self.min_interval = 1.0 / self.calls_per_second

# Global adaptive rate limiter
rate_limiter = AdaptiveRateLimiter(initial_calls_per_second=0.8)

def smart_retry(max_retries=5, base_delay=2):
    """429 hatalarÄ±na Ã¶zel akÄ±llÄ± retry decorator"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    result = func(*args, **kwargs)
                    rate_limiter.report_success()
                    return result
                except requests.exceptions.HTTPError as e:
                    if e.response.status_code == 429:
                        rate_limiter.report_429()
                        # 429 iÃ§in Ã¶zel bekleme sÃ¼resi
                        wait_time = base_delay * (3 ** attempt) + (attempt * 2)
                        print(f"ğŸ”„ 429 HatasÄ± - Deneme {attempt + 1}/{max_retries}, {wait_time}s bekleniyor...")
                        time.sleep(wait_time)
                    else:
                        print(f"ğŸ”„ HTTP HatasÄ± {e.response.status_code} - Deneme {attempt + 1}/{max_retries}")
                        time.sleep(base_delay * (2 ** attempt))
                    
                    if attempt == max_retries - 1:
                        raise e
                except Exception as e:
                    if attempt == max_retries - 1:
                        raise e
                    print(f"ğŸ”„ Genel Hata - Deneme {attempt + 1}/{max_retries}: {e}")
                    time.sleep(base_delay * (2 ** attempt))
            return None
        return wrapper
    return decorator

def daterange(start_date, end_date):
    """Tarih aralÄ±ÄŸÄ±nÄ± gÃ¼n gÃ¼n dÃ¶ndÃ¼rÃ¼r"""
    for n in range(int((end_date - start_date).days) + 1):
        yield start_date + timedelta(n)

@smart_retry(max_retries=5, base_delay=3)
def get_point_data(lat, lon, date_str):
    """Tek nokta iÃ§in NASA POWER point sorgusu - cache ve rate limiting ile"""
    # Cache kontrolÃ¼
    cache_key = get_cache_key(lat, lon, date_str)
    cached_data = get_from_cache(cache_key)
    if cached_data:
        return cached_data
    
    # Rate limiting
    rate_limiter.wait_if_needed()
    
    date_api = datetime.strptime(date_str, "%Y-%m-%d").strftime("%Y%m%d")
    url = "https://power.larc.nasa.gov/api/temporal/daily/point"
    params = {
        "parameters": "T2M,WS10M,PRECTOTCORR,RH2M",
        "community": "RE",
        "longitude": lon,
        "latitude": lat,
        "start": date_api,
        "end": date_api,
        "format": "JSON"
    }
    
    response = requests.get(url, params=params, timeout=30)
    response.raise_for_status()
    data = response.json()
    params_data = data["properties"]["parameter"]
    
    # Verileri hazÄ±rla
    result = {
        "temperature": list(params_data["T2M"].values())[0],
        "wind_speed": list(params_data["WS10M"].values())[0],
        "precipitation": list(params_data["PRECTOTCORR"].values())[0],
        "humidity": list(params_data["RH2M"].values())[0],
        "lat": lat,
        "lon": lon,
        "date": date_str
    }
    
    # Cache'e kaydet
    save_to_cache(cache_key, result)
    return result

def fetch_data_parallel(coordinates_list, max_workers=2):
    """Konservatif paralel veri Ã§ekme (NASA API rate limits iÃ§in)"""
    results = []
    failed_coords = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Future'larÄ± hazÄ±rla
        future_to_coord = {
            executor.submit(get_point_data, coord[0], coord[1], coord[2]): coord 
            for coord in coordinates_list
        }
        
        for future in concurrent.futures.as_completed(future_to_coord):
            coord = future_to_coord[future]
            try:
                result = future.result()
                results.append(result)
            except Exception as e:
                failed_coords.append((coord, str(e)))
    
    return results, failed_coords

def process_data_batch(data_points, batch_size=100):
    """Memory efficient batch processing"""
    for i in range(0, len(data_points), batch_size):
        yield data_points[i:i + batch_size]

def calculate_statistics(all_data):
    """Memory efficient statistics calculation"""
    if not all_data:
        raise Exception("HiÃ§ veri alÄ±namadÄ±.")
    
    # Ä°lk parametreleri al
    keys = [k for k in all_data[0].keys() if k not in ['lat', 'lon', 'date']]
    
    # Memory efficient hesaplama
    stats = {}
    for key in keys:
        values = [d[key] for d in all_data if key in d and d[key] is not None]
        if values:
            stats[key] = {
                'average': sum(values) / len(values),
                'minimum': min(values),
                'maximum': max(values),
                'count': len(values)
            }
    
    return stats

def calculate_weather_risks(all_data):
    """Weather risk thresholds based on NASA challenge requirements"""
    if not all_data:
        return {}
    
    # Threshold deÄŸerleri (extreme weather events)
    thresholds = {
        'very_hot': 32.2,      # 90Â°F = 32.2Â°C
        'very_cold': 0.0,      # 32Â°F = 0Â°C
        'very_windy': 15.0,    # 15 m/s (~33 mph)
        'very_wet': 10.0,      # 10mm yaÄŸÄ±ÅŸ
        'very_humid': 85.0     # %85 nem (uncomfortable)
    }
    
    total_points = len(all_data)
    risks = {}
    
    # Very Hot Risk
    hot_count = sum(1 for d in all_data if d.get('temperature', 0) > thresholds['very_hot'])
    risks['very_hot'] = {
        'probability': (hot_count / total_points) * 100,
        'threshold': thresholds['very_hot'],
        'description': f"SÄ±caklÄ±k {thresholds['very_hot']}Â°C Ã¼zerinde",
        'risk_level': 'high' if hot_count/total_points > 0.3 else 'medium' if hot_count/total_points > 0.1 else 'low'
    }
    
    # Very Cold Risk
    cold_count = sum(1 for d in all_data if d.get('temperature', 0) < thresholds['very_cold'])
    risks['very_cold'] = {
        'probability': (cold_count / total_points) * 100,
        'threshold': thresholds['very_cold'],
        'description': f"SÄ±caklÄ±k {thresholds['very_cold']}Â°C altÄ±nda",
        'risk_level': 'high' if cold_count/total_points > 0.3 else 'medium' if cold_count/total_points > 0.1 else 'low'
    }
    
    # Very Windy Risk
    windy_count = sum(1 for d in all_data if d.get('wind_speed', 0) > thresholds['very_windy'])
    risks['very_windy'] = {
        'probability': (windy_count / total_points) * 100,
        'threshold': thresholds['very_windy'],
        'description': f"RÃ¼zgar hÄ±zÄ± {thresholds['very_windy']} m/s Ã¼zerinde",
        'risk_level': 'high' if windy_count/total_points > 0.3 else 'medium' if windy_count/total_points > 0.1 else 'low'
    }
    
    # Very Wet Risk
    wet_count = sum(1 for d in all_data if d.get('precipitation', 0) > thresholds['very_wet'])
    risks['very_wet'] = {
        'probability': (wet_count / total_points) * 100,
        'threshold': thresholds['very_wet'],
        'description': f"YaÄŸÄ±ÅŸ {thresholds['very_wet']} mm Ã¼zerinde",
        'risk_level': 'high' if wet_count/total_points > 0.3 else 'medium' if wet_count/total_points > 0.1 else 'low'
    }
    
    # Very Humid Risk (uncomfortable)
    humid_count = sum(1 for d in all_data if d.get('humidity', 0) > thresholds['very_humid'])
    risks['very_uncomfortable'] = {
        'probability': (humid_count / total_points) * 100,
        'threshold': thresholds['very_humid'],
        'description': f"Nem oranÄ± %{thresholds['very_humid']} Ã¼zerinde",
        'risk_level': 'high' if humid_count/total_points > 0.3 else 'medium' if humid_count/total_points > 0.1 else 'low'
    }
    
    # Overall risk assessment
    high_risk_count = sum(1 for risk in risks.values() if risk['risk_level'] == 'high')
    risks['overall_assessment'] = {
        'risk_level': 'high' if high_risk_count >= 2 else 'medium' if high_risk_count == 1 else 'low',
        'recommendation': get_risk_recommendation(risks)
    }
    
    return risks

def get_risk_recommendation(risks):
    """Generate recommendation based on risk analysis"""
    high_risks = [name for name, data in risks.items() if data.get('risk_level') == 'high']
    
    if not high_risks:
        return "âœ… Hava koÅŸullarÄ± outdoor aktiviteler iÃ§in uygun gÃ¶rÃ¼nÃ¼yor."
    
    recommendations = {
        'very_hot': "ğŸŒ¡ï¸ AÅŸÄ±rÄ± sÄ±cak olabilir. Bol su iÃ§in ve gÃ¶lgelik alanlarÄ± tercih edin.",
        'very_cold': "ğŸ¥¶ Ã‡ok soÄŸuk olabilir. SÄ±cak giyinin ve soÄŸuk hava ekipmanlarÄ± getirin.",
        'very_windy': "ğŸ’¨ Ã‡ok rÃ¼zgarlÄ± olabilir. AÃ§Ä±k alanda aktivite planlarÄ±nÄ±zÄ± gÃ¶zden geÃ§irin.",
        'very_wet': "ğŸŒ§ï¸ YaÄŸÄ±ÅŸlÄ± olabilir. Su geÃ§irmez ekipman ve kapalÄ± alan alternatifleri hazÄ±rlayÄ±n.",
        'very_uncomfortable': "ğŸ’§ Nem oranÄ± yÃ¼ksek olabilir. FerahlatÄ±cÄ± iÃ§ecekler ve serin ortam tercih edin."
    }
    
    advice = "âš ï¸ Risk faktÃ¶rleri: " + ", ".join([recommendations.get(risk, risk) for risk in high_risks])
    return advice

def get_area_average(lat_min, lat_max, lon_min, lon_max, start_date_str, end_date_str, step=1.0, progress_callback=None):
    """
    Alan ve tarih aralÄ±ÄŸÄ± iÃ§in ortalama/min/max hesaplar - optimized version
    step: alan grid adÄ±mÄ± (Â°)
    progress_callback: ilerleme durumu iÃ§in callback fonksiyonu
    """
    start_date = datetime.strptime(start_date_str, "%Y-%m-%d")
    end_date = datetime.strptime(end_date_str, "%Y-%m-%d")
    
    lat_points = [lat_min + i*step for i in range(int((lat_max - lat_min)/step) + 1)]
    lon_points = [lon_min + i*step for i in range(int((lon_max - lon_min)/step) + 1)]
    
    # TÃ¼m koordinat-tarih kombinasyonlarÄ±nÄ± hazÄ±rla
    coordinates_list = []
    for single_date in daterange(start_date, end_date):
        date_str = single_date.strftime("%Y-%m-%d")
        for lat in lat_points:
            for lon in lon_points:
                coordinates_list.append((lat, lon, date_str))
    
    total_operations = len(coordinates_list)
    print(f"ğŸ“Š Toplam {total_operations} veri noktasÄ± iÅŸlenecek...")
    print("ğŸš€ Paralel iÅŸleme baÅŸlÄ±yor...")
    
    # Konservatif paralel iÅŸlem iÃ§in kÃ¼Ã§Ã¼k batch'lere ayÄ±r
    batch_size = 20  # Her batch'te 20 koordinat (NASA API'ye nazik olalÄ±m)
    all_data = []
    processed = 0
    
    # Progress bar
    with tqdm(total=total_operations, desc="ğŸŒ Konservatif veri toplama", unit="nokta") as pbar:
        for i in range(0, len(coordinates_list), batch_size):
            batch = coordinates_list[i:i + batch_size]
            
            # Bu batch'i paralel olarak iÅŸle (sadece 2 thread)
            batch_results, failed_coords = fetch_data_parallel(batch, max_workers=2)
            
            all_data.extend(batch_results)
            processed += len(batch)
            pbar.update(len(batch))
            
            # Progress callback
            if progress_callback:
                progress_callback(processed, total_operations)
            
            # BaÅŸarÄ±sÄ±z olanlarÄ± logla
            if failed_coords:
                for coord, error in failed_coords:
                    print(f"âš ï¸ Hata: {error} at {coord[0]:.2f},{coord[1]:.2f} on {coord[2]}")
            
            # NASA API'ye saygÄ±: batch'ler arasÄ± daha uzun bekleme
            if i + batch_size < len(coordinates_list):
                wait_time = 3 + (rate_limiter.consecutive_429s * 2)  # 429'lar arttÄ±kÃ§a daha uzun bekle
                print(f"â³ Batch arasÄ± {wait_time}s bekleme...")
                time.sleep(wait_time)
    
    # Ä°statistikleri hesapla
    print("ğŸ“ˆ Ä°statistikler hesaplanÄ±yor...")
    stats = calculate_statistics(all_data)
    
    # Risk analizi ekle
    risk_analysis = calculate_weather_risks(all_data)
    
    return {
        "statistics": stats,
        "risk_analysis": risk_analysis,
        "raw_data": all_data[:100],  # Sadece ilk 100 veri noktasÄ±nÄ± dÃ¶ndÃ¼r
        "total_points": len(all_data),
        "date_range": f"{start_date_str} - {end_date_str}",
        "coordinates": f"({lat_min},{lon_min}) - ({lat_max},{lon_max})",
        "all_data": all_data,  # Grafik iÃ§in tÃ¼m veri
        "cache_hits": sum(1 for coord in coordinates_list if get_from_cache(get_cache_key(*coord))),
        "processing_time": time.time()
    }

def create_weather_charts(data, output_dir="charts"):
    """Hava durumu verilerini grafikleÅŸtirir"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # Verileri tarihe gÃ¶re grupla
    date_data = defaultdict(list)
    for point in data['all_data']:
        date_data[point['date']].append(point)
    
    # GÃ¼nlÃ¼k ortalamalar
    dates = []
    temp_avg = []
    wind_avg = []
    precip_avg = []
    humidity_avg = []
    
    for date_str in sorted(date_data.keys()):
        points = date_data[date_str]
        dates.append(datetime.strptime(date_str, "%Y-%m-%d"))
        
        # GÃ¼nlÃ¼k ortalamalar
        temp_avg.append(np.mean([p['temperature'] for p in points]))
        wind_avg.append(np.mean([p['wind_speed'] for p in points]))
        precip_avg.append(np.mean([p['precipitation'] for p in points]))
        humidity_avg.append(np.mean([p['humidity'] for p in points]))
    
    # 4 subplot oluÅŸtur
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('ğŸŒ NASA POWER Hava Durumu Analizi', fontsize=16, fontweight='bold')
    
    # SÄ±caklÄ±k grafiÄŸi
    ax1.plot(dates, temp_avg, 'r-', linewidth=2, marker='o', markersize=4)
    ax1.set_title('ğŸŒ¡ï¸ SÄ±caklÄ±k (Â°C)')
    ax1.set_ylabel('SÄ±caklÄ±k (Â°C)')
    ax1.grid(True, alpha=0.3)
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    
    # RÃ¼zgar hÄ±zÄ± grafiÄŸi
    ax2.plot(dates, wind_avg, 'b-', linewidth=2, marker='s', markersize=4)
    ax2.set_title('ğŸ’¨ RÃ¼zgar HÄ±zÄ± (m/s)')
    ax2.set_ylabel('RÃ¼zgar HÄ±zÄ± (m/s)')
    ax2.grid(True, alpha=0.3)
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    
    # YaÄŸÄ±ÅŸ grafiÄŸi
    ax3.bar(dates, precip_avg, color='skyblue', alpha=0.7, width=0.8)
    ax3.set_title('ğŸŒ§ï¸ YaÄŸÄ±ÅŸ (mm)')
    ax3.set_ylabel('YaÄŸÄ±ÅŸ (mm)')
    ax3.grid(True, alpha=0.3)
    ax3.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    
    # Nem grafiÄŸi
    ax4.fill_between(dates, humidity_avg, alpha=0.5, color='green')
    ax4.plot(dates, humidity_avg, 'g-', linewidth=2)
    ax4.set_title('ğŸ’§ Nem (%)')
    ax4.set_ylabel('Nem (%)')
    ax4.grid(True, alpha=0.3)
    ax4.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d'))
    
    # Layout dÃ¼zenle
    plt.tight_layout()
    
    # GrafiÄŸi kaydet
    chart_path = os.path.join(output_dir, 'weather_analysis.png')
    plt.savefig(chart_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š Grafik kaydedildi: {chart_path}")
    
    # Ä°statistik grafiÄŸi
    fig2, ax = plt.subplots(figsize=(12, 8))
    stats = data['statistics']
    
    categories = list(stats.keys())
    averages = [stats[cat]['average'] for cat in categories]
    minimums = [stats[cat]['minimum'] for cat in categories]
    maximums = [stats[cat]['maximum'] for cat in categories]
    
    x = np.arange(len(categories))
    width = 0.25
    
    ax.bar(x - width, averages, width, label='Ortalama', alpha=0.8)
    ax.bar(x, minimums, width, label='Minimum', alpha=0.8)
    ax.bar(x + width, maximums, width, label='Maksimum', alpha=0.8)
    
    ax.set_xlabel('Parametreler')
    ax.set_ylabel('DeÄŸerler')
    ax.set_title('ğŸ“ˆ Hava Durumu Ä°statistikleri')
    ax.set_xticks(x)
    ax.set_xticklabels(categories)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    stats_path = os.path.join(output_dir, 'weather_statistics.png')
    plt.savefig(stats_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ“ˆ Ä°statistik grafiÄŸi kaydedildi: {stats_path}")
    
    plt.show()  # Grafikleri gÃ¶ster
    
    return [chart_path, stats_path]

# --- Console Mode ---
def run_console_mode():
    """Console modunda Ã§alÄ±ÅŸtÄ±r"""
    print("ğŸŒ NASA Weather Risk Checker (Grid Area + Long Range) ğŸŒ")
    print("ğŸ“± Web arayÃ¼zÃ¼ iÃ§in: python app.py")
    print("=" * 50)
    
    try:
        lat_min = float(input("Min enlem: "))
        lat_max = float(input("Max enlem: "))
        lon_min = float(input("Min boylam: "))
        lon_max = float(input("Max boylam: "))
        start_date = input("BaÅŸlangÄ±Ã§ tarihi (YYYY-MM-DD): ")
        end_date = input("BitiÅŸ tarihi (YYYY-MM-DD): ")
        step = float(input("Grid adÄ±mÄ± (varsayÄ±lan 1.0): ") or "1.0")
        
        print("\nğŸš€ Analiz baÅŸlÄ±yor...")
        result = get_area_average(lat_min, lat_max, lon_min, lon_max, start_date, end_date, step=step)
        
        print("\n" + "="*50)
        print("ğŸ“Š SONUÃ‡LAR")
        print("="*50)
        
        stats = result["statistics"]
        for param, data in stats.items():
            print(f"\nğŸŒ¡ï¸ {param.upper()}:")
            print(f"   Ortalama: {data['average']:.2f}")
            print(f"   Minimum:  {data['minimum']:.2f}")
            print(f"   Maksimum: {data['maximum']:.2f}")
        
        print(f"\nğŸ“ˆ Toplam veri noktasÄ±: {result['total_points']}")
        print(f"ğŸ“… Tarih aralÄ±ÄŸÄ±: {result['date_range']}")
        print(f"ğŸ—ºï¸ Koordinat aralÄ±ÄŸÄ±: {result['coordinates']}")
        
        # Grafik sor
        create_charts = input("\nï¿½ Grafikler oluÅŸturulsun mu? (e/h): ").lower().startswith('e')
        if create_charts:
            chart_paths = create_weather_charts(result)
            print(f"âœ… Grafikler oluÅŸturuldu: {chart_paths}")
        
    except KeyboardInterrupt:
        print("\nâŒ Ä°ÅŸlem iptal edildi.")
    except Exception as e:
        print(f"\nâŒ Hata: {e}")

if __name__ == "__main__":
    run_console_mode()
